# ğŸ› ï¸ é‹ç”¨ç®¡ç†ãƒ»ç›£è¦–ã‚¬ã‚¤ãƒ‰

## ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ç›£è¦–ãƒ»ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

### ğŸ¯ ç›£è¦–å¯¾è±¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹

#### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤
- **ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“**: APIãƒ»ç”»é¢è¡¨ç¤ºé€Ÿåº¦
- **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: åŒæ™‚æ¥ç¶šæ•°ãƒ»ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†æ•°
- **ã‚¨ãƒ©ãƒ¼ç‡**: HTTP 4xx/5xx ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿç‡
- **å¯ç”¨æ€§**: ã‚µãƒ¼ãƒ“ã‚¹ç¨¼åƒç‡ãƒ»ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ 
- **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚»ãƒƒã‚·ãƒ§ãƒ³**: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶™ç¶šæ™‚é–“

#### ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£å±¤
- **CPUä½¿ç”¨ç‡**: ã‚µãƒ¼ãƒãƒ¼ãƒ»ã‚³ãƒ³ãƒ†ãƒŠãƒªã‚½ãƒ¼ã‚¹
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª
- **ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡**: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®¹é‡ãƒ»I/Oæ€§èƒ½
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: å¸¯åŸŸä½¿ç”¨ç‡ãƒ»ãƒ‘ã‚±ãƒƒãƒˆæå¤±
- **ã‚³ãƒ³ãƒ†ãƒŠãƒ˜ãƒ«ã‚¹**: Docker ã‚³ãƒ³ãƒ†ãƒŠç¨¼åƒçŠ¶æ³

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å±¤
- **æ¥ç¶šæ•°**: ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ»ã‚¢ã‚¤ãƒ‰ãƒ«æ¥ç¶š
- **ã‚¯ã‚¨ãƒªæ€§èƒ½**: å®Ÿè¡Œæ™‚é–“ãƒ»ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒª
- **ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**: ãƒã‚¹ã‚¿ãƒ¼ãƒ»ã‚¹ãƒ¬ãƒ¼ãƒ–åŒæœŸçŠ¶æ³
- **ãƒ­ãƒƒã‚¯**: ãƒ‡ãƒƒãƒ‰ãƒ­ãƒƒã‚¯ãƒ»ãƒ­ãƒƒã‚¯å¾…æ©Ÿæ™‚é–“
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**: è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆåŠŸãƒ»å¤±æ•—

### ğŸ“ˆ Grafana ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š

```yaml
# grafana/dashboards/shiftmaster-overview.json
{
  "dashboard": {
    "title": "ShiftMaster - ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦",
    "panels": [
      {
        "title": "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"shiftmaster\"}"
          }
        ]
      },
      {
        "title": "ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(django_request_duration_seconds_bucket[5m]))"
          }
        ]
      },
      {
        "title": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š",
        "type": "graph", 
        "targets": [
          {
            "expr": "pg_stat_activity_count"
          }
        ]
      }
    ]
  }
}
```

### ğŸš¨ Prometheus ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

```yaml
# prometheus/alerts/shiftmaster.yml
groups:
  - name: shiftmaster.alerts
    rules:
      # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åœæ­¢
      - alert: ShiftMasterDown
        expr: up{job="shiftmaster"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "ShiftMaster application is down"
          description: "ShiftMaster has been down for more than 30 seconds"

      # é«˜ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(django_request_duration_seconds_bucket[5m])) > 2
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"

      # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼
      - alert: DatabaseConnectionError
        expr: pg_up == 0
        for: 10s
        labels:
          severity: critical
        annotations:
          summary: "PostgreSQL database is down"

      # é«˜CPUä½¿ç”¨ç‡
      - alert: HighCPUUsage
        expr: (100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[2m])) * 100)) > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"

      # ãƒ¡ãƒ¢ãƒªä¸è¶³
      - alert: HighMemoryUsage
        expr: ((node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes) * 100 > 85
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"

      # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³
      - alert: DiskSpaceWarning
        expr: ((node_filesystem_size_bytes{fstype!="tmpfs"} - node_filesystem_free_bytes{fstype!="tmpfs"}) / node_filesystem_size_bytes{fstype!="tmpfs"}) * 100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Disk space usage is high"
```

## ğŸ”” ã‚¢ãƒ©ãƒ¼ãƒˆãƒ»é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 

### ğŸ“§ é€šçŸ¥ãƒãƒ£ãƒ³ãƒãƒ«è¨­å®š

```yaml
# alertmanager/config.yml
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@shiftmaster.local'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
  - name: 'web.hook'
    email_configs:
      - to: 'admin@hospital.local'
        subject: '[ShiftMaster] {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          {{ end }}
    
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX'
        channel: '#shiftmaster-alerts'
        title: 'ShiftMaster Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname']
```

### ğŸ“± PagerDuty çµ±åˆ

```python
# monitoring/pagerduty_integration.py
import requests
import json
from django.conf import settings

class PagerDutyAlert:
    def __init__(self):
        self.integration_key = settings.PAGERDUTY_INTEGRATION_KEY
        self.api_url = "https://events.pagerduty.com/v2/enqueue"
    
    def trigger_alert(self, summary, severity, details=None):
        """ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆã‚’PagerDutyã«é€ä¿¡"""
        payload = {
            "routing_key": self.integration_key,
            "event_action": "trigger",
            "payload": {
                "summary": summary,
                "severity": severity,
                "source": "shiftmaster",
                "custom_details": details or {}
            }
        }
        
        response = requests.post(
            self.api_url,
            data=json.dumps(payload),
            headers={'Content-Type': 'application/json'}
        )
        
        return response.status_code == 202
    
    def resolve_alert(self, dedup_key):
        """ã‚¢ãƒ©ãƒ¼ãƒˆè§£æ±ºã‚’PagerDutyã«é€šçŸ¥"""
        payload = {
            "routing_key": self.integration_key,
            "event_action": "resolve",
            "dedup_key": dedup_key
        }
        
        response = requests.post(
            self.api_url,
            data=json.dumps(payload),
            headers={'Content-Type': 'application/json'}
        )
        
        return response.status_code == 202

# ä½¿ç”¨ä¾‹
def check_critical_systems():
    """é‡è¦ã‚·ã‚¹ãƒ†ãƒ ã®å®šæœŸãƒã‚§ãƒƒã‚¯"""
    pager = PagerDutyAlert()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒã‚§ãƒƒã‚¯
    if not check_database_connection():
        pager.trigger_alert(
            "Database connection failed",
            "critical",
            {"component": "postgresql", "timestamp": datetime.now().isoformat()}
        )
```

## ğŸ”§ è‡ªå‹•åŒ–é‹ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### ğŸ“Š ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯è‡ªå‹•åŒ–

```python
# monitoring/health_checker.py
#!/usr/bin/env python
"""
ShiftMaster ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯è‡ªå‹•åŒ–
"""

import subprocess
import requests
import psycopg2
import redis
import smtplib
from email.mime.text import MIMEText
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HealthChecker:
    def __init__(self):
        self.checks = [
            self.check_web_service,
            self.check_database,
            self.check_redis,
            self.check_celery,
            self.check_nginx,
            self.check_disk_space,
            self.check_memory_usage
        ]
        self.results = []
    
    def check_web_service(self):
        """Webã‚µãƒ¼ãƒ“ã‚¹æ­»æ´»ç›£è¦–"""
        try:
            response = requests.get("http://localhost:8000/health/", timeout=10)
            if response.status_code == 200:
                return {"service": "web", "status": "healthy", "response_time": response.elapsed.total_seconds()}
            else:
                return {"service": "web", "status": "unhealthy", "error": f"HTTP {response.status_code}"}
        except Exception as e:
            return {"service": "web", "status": "down", "error": str(e)}
    
    def check_database(self):
        """PostgreSQLæ¥ç¶šãƒã‚§ãƒƒã‚¯"""
        try:
            conn = psycopg2.connect(
                host="localhost",
                database="shiftmaster",
                user="postgres",
                password="password"
            )
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            cursor.close()
            conn.close()
            return {"service": "database", "status": "healthy"}
        except Exception as e:
            return {"service": "database", "status": "down", "error": str(e)}
    
    def check_redis(self):
        """Redisæ¥ç¶šãƒã‚§ãƒƒã‚¯"""
        try:
            r = redis.Redis(host='localhost', port=6379, db=0)
            r.ping()
            return {"service": "redis", "status": "healthy"}
        except Exception as e:
            return {"service": "redis", "status": "down", "error": str(e)}
    
    def check_celery(self):
        """Celery Workerç¨¼åƒãƒã‚§ãƒƒã‚¯"""
        try:
            result = subprocess.run(
                ["celery", "-A", "shiftmaster", "inspect", "active"],
                capture_output=True, text=True, timeout=30
            )
            if result.returncode == 0:
                return {"service": "celery", "status": "healthy"}
            else:
                return {"service": "celery", "status": "down", "error": result.stderr}
        except Exception as e:
            return {"service": "celery", "status": "down", "error": str(e)}
    
    def check_nginx(self):
        """Nginxç¨¼åƒãƒã‚§ãƒƒã‚¯"""
        try:
            result = subprocess.run(
                ["systemctl", "is-active", "nginx"],
                capture_output=True, text=True
            )
            if result.stdout.strip() == "active":
                return {"service": "nginx", "status": "healthy"}
            else:
                return {"service": "nginx", "status": "down", "error": "Service not active"}
        except Exception as e:
            return {"service": "nginx", "status": "down", "error": str(e)}
    
    def check_disk_space(self):
        """ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãƒã‚§ãƒƒã‚¯"""
        try:
            result = subprocess.run(
                ["df", "-h", "/"],
                capture_output=True, text=True
            )
            lines = result.stdout.strip().split('\n')
            if len(lines) >= 2:
                usage_line = lines[1].split()
                usage_percent = int(usage_line[4].rstrip('%'))
                
                status = "healthy"
                if usage_percent > 90:
                    status = "critical"
                elif usage_percent > 80:
                    status = "warning"
                
                return {
                    "service": "disk_space",
                    "status": status,
                    "usage_percent": usage_percent
                }
        except Exception as e:
            return {"service": "disk_space", "status": "error", "error": str(e)}
    
    def check_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯"""
        try:
            result = subprocess.run(
                ["free", "-m"],
                capture_output=True, text=True
            )
            lines = result.stdout.strip().split('\n')
            mem_line = lines[1].split()
            
            total = int(mem_line[1])
            used = int(mem_line[2])
            usage_percent = (used / total) * 100
            
            status = "healthy"
            if usage_percent > 90:
                status = "critical"
            elif usage_percent > 80:
                status = "warning"
            
            return {
                "service": "memory",
                "status": status,
                "usage_percent": round(usage_percent, 2)
            }
        except Exception as e:
            return {"service": "memory", "status": "error", "error": str(e)}
    
    def run_all_checks(self):
        """å…¨ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        logger.info("Starting health checks...")
        
        for check in self.checks:
            try:
                result = check()
                result["timestamp"] = datetime.now().isoformat()
                self.results.append(result)
                logger.info(f"Check {result['service']}: {result['status']}")
            except Exception as e:
                logger.error(f"Error running check {check.__name__}: {e}")
        
        return self.results
    
    def generate_report(self):
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report = []
        report.append("=== ShiftMaster System Health Report ===")
        report.append(f"Report generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        healthy_count = 0
        for result in self.results:
            status = result['status']
            service = result['service']
            
            if status == "healthy":
                healthy_count += 1
                status_icon = "âœ…"
            elif status == "warning":
                status_icon = "âš ï¸"
            elif status in ["unhealthy", "down", "critical"]:
                status_icon = "âŒ"
            else:
                status_icon = "â“"
            
            report.append(f"{status_icon} {service.upper()}: {status}")
            
            if "error" in result:
                report.append(f"   Error: {result['error']}")
            if "usage_percent" in result:
                report.append(f"   Usage: {result['usage_percent']}%")
            if "response_time" in result:
                report.append(f"   Response time: {result['response_time']:.3f}s")
        
        report.append("")
        report.append(f"Overall health: {healthy_count}/{len(self.results)} services healthy")
        
        return "\n".join(report)
    
    def send_alert_email(self, report):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¡ãƒ¼ãƒ«é€ä¿¡"""
        try:
            msg = MIMEText(report)
            msg['Subject'] = 'ShiftMaster System Health Alert'
            msg['From'] = 'system@shiftmaster.local'
            msg['To'] = 'admin@hospital.local'
            
            server = smtplib.SMTP('localhost')
            server.send_message(msg)
            server.quit()
            
            logger.info("Alert email sent successfully")
        except Exception as e:
            logger.error(f"Failed to send alert email: {e}")

if __name__ == "__main__":
    checker = HealthChecker()
    results = checker.run_all_checks()
    report = checker.generate_report()
    
    print(report)
    
    # å•é¡ŒãŒã‚ã‚‹å ´åˆã¯ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¡ãƒ¼ãƒ«é€ä¿¡
    critical_issues = [r for r in results if r['status'] in ['down', 'critical', 'unhealthy']]
    if critical_issues:
        checker.send_alert_email(report)
```

### ğŸ”„ è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»å¾©æ—§

```bash
#!/bin/bash
# monitoring/backup_automation.sh

set -e

# è¨­å®š
BACKUP_DIR="/var/backups/shiftmaster"
DB_NAME="shiftmaster"
DB_USER="postgres"
RETENTION_DAYS=30
DATE=$(date +%Y%m%d_%H%M%S)
SLACK_WEBHOOK="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"

# ãƒ­ã‚°è¨­å®š
LOG_FILE="/var/log/shiftmaster/backup.log"
exec 1> >(tee -a $LOG_FILE)
exec 2>&1

echo "=== ShiftMaster Backup Started: $(date) ==="

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p $BACKUP_DIR

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "Creating database backup..."
pg_dump -U $DB_USER -h localhost $DB_NAME | gzip > "$BACKUP_DIR/db_backup_$DATE.sql.gz"

if [ $? -eq 0 ]; then
    echo "âœ… Database backup completed successfully"
    DB_BACKUP_STATUS="SUCCESS"
else
    echo "âŒ Database backup failed"
    DB_BACKUP_STATUS="FAILED"
fi

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "Creating application files backup..."
tar -czf "$BACKUP_DIR/app_backup_$DATE.tar.gz" \
    --exclude="__pycache__" \
    --exclude="*.pyc" \
    --exclude=".git" \
    --exclude="new_env" \
    /path/to/shiftmaster/

if [ $? -eq 0 ]; then
    echo "âœ… Application backup completed successfully"
    APP_BACKUP_STATUS="SUCCESS"
else
    echo "âŒ Application backup failed"
    APP_BACKUP_STATUS="FAILED"
fi

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
echo "Creating configuration backup..."
tar -czf "$BACKUP_DIR/config_backup_$DATE.tar.gz" \
    /etc/nginx/sites-available/shiftmaster \
    /etc/systemd/system/shiftmaster.service \
    /etc/ssl/private/shiftmaster.key \
    /etc/ssl/certs/shiftmaster.crt

if [ $? -eq 0 ]; then
    echo "âœ… Configuration backup completed successfully"
    CONFIG_BACKUP_STATUS="SUCCESS"
else
    echo "âŒ Configuration backup failed"
    CONFIG_BACKUP_STATUS="FAILED"
fi

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
echo "Cleaning up old backups..."
find $BACKUP_DIR -type f -mtime +$RETENTION_DAYS -delete

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚ºè¨ˆç®—
BACKUP_SIZE=$(du -sh $BACKUP_DIR | cut -f1)

# Slackã«çµæœé€šçŸ¥
BACKUP_REPORT="ShiftMaster Backup Report
Date: $(date)
Database: $DB_BACKUP_STATUS
Application: $APP_BACKUP_STATUS
Configuration: $CONFIG_BACKUP_STATUS
Total size: $BACKUP_SIZE
Location: $BACKUP_DIR"

curl -X POST -H 'Content-type: application/json' \
    --data "{\"text\":\"$BACKUP_REPORT\"}" \
    $SLACK_WEBHOOK

echo "=== ShiftMaster Backup Completed: $(date) ==="
```

### ğŸš€ è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ»ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

```python
# monitoring/deployment_automation.py
#!/usr/bin/env python
"""
ShiftMaster è‡ªå‹•ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ»ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
"""

import subprocess
import sys
import os
import time
import requests
from datetime import datetime

class DeploymentManager:
    def __init__(self):
        self.app_path = "/var/www/shiftmaster"
        self.service_name = "shiftmaster"
        self.backup_path = "/var/backups/shiftmaster/deployments"
        
    def backup_current_deployment(self):
        """ç¾åœ¨ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = f"{self.backup_path}/backup_{timestamp}"
        
        print(f"Creating deployment backup: {backup_dir}")
        
        subprocess.run([
            "cp", "-r", self.app_path, backup_dir
        ], check=True)
        
        return backup_dir
    
    def health_check(self, max_attempts=5, delay=10):
        """ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        for attempt in range(max_attempts):
            try:
                response = requests.get("http://localhost:8000/health/", timeout=10)
                if response.status_code == 200:
                    print("âœ… Health check passed")
                    return True
            except Exception as e:
                print(f"Health check attempt {attempt + 1} failed: {e}")
                
            if attempt < max_attempts - 1:
                print(f"Waiting {delay} seconds before next attempt...")
                time.sleep(delay)
        
        print("âŒ Health check failed")
        return False
    
    def deploy(self, git_branch="main"):
        """æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤"""
        print(f"=== Starting deployment from branch: {git_branch} ===")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_dir = self.backup_current_deployment()
        
        try:
            # Gitãƒ—ãƒ«ã—ã¦ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆKa
            print("Updating application code...")
            subprocess.run([
                "git", "-C", self.app_path, "fetch", "origin"
            ], check=True)
            
            subprocess.run([
                "git", "-C", self.app_path, "checkout", git_branch
            ], check=True)
            
            subprocess.run([
                "git", "-C", self.app_path, "pull", "origin", git_branch
            ], check=True)
            
            # ä¾å­˜é–¢ä¿‚æ›´æ–°
            print("Installing dependencies...")
            subprocess.run([
                "pip", "install", "-r", f"{self.app_path}/requirements.txt"
            ], check=True)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            print("Running database migrations...")
            subprocess.run([
                "python", f"{self.app_path}/manage.py", "migrate"
            ], check=True)
            
            # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«åé›†
            print("Collecting static files...")
            subprocess.run([
                "python", f"{self.app_path}/manage.py", "collectstatic", "--noinput"
            ], check=True)
            
            # ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
            print("Restarting application service...")
            subprocess.run([
                "systemctl", "restart", self.service_name
            ], check=True)
            
            # Nginxå†èª­ã¿è¾¼ã¿
            subprocess.run([
                "systemctl", "reload", "nginx"
            ], check=True)
            
            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
            print("Performing health check...")
            if self.health_check():
                print("âœ… Deployment completed successfully!")
                return True
            else:
                print("âŒ Deployment failed health check")
                self.rollback(backup_dir)
                return False
                
        except subprocess.CalledProcessError as e:
            print(f"âŒ Deployment failed: {e}")
            self.rollback(backup_dir)
            return False
    
    def rollback(self, backup_dir):
        """å‰ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        print(f"=== Starting rollback to: {backup_dir} ===")
        
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ
            subprocess.run([
                "rm", "-rf", f"{self.app_path}.old"
            ])
            
            subprocess.run([
                "mv", self.app_path, f"{self.app_path}.old"
            ], check=True)
            
            subprocess.run([
                "mv", backup_dir, self.app_path
            ], check=True)
            
            # ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
            subprocess.run([
                "systemctl", "restart", self.service_name
            ], check=True)
            
            subprocess.run([
                "systemctl", "reload", "nginx"
            ], check=True)
            
            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
            if self.health_check():
                print("âœ… Rollback completed successfully!")
                return True
            else:
                print("âŒ Rollback failed health check")
                return False
                
        except subprocess.CalledProcessError as e:
            print(f"âŒ Rollback failed: {e}")
            return False

if __name__ == "__main__":
    manager = DeploymentManager()
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "deploy":
            branch = sys.argv[2] if len(sys.argv) > 2 else "main"
            success = manager.deploy(branch)
            sys.exit(0 if success else 1)
        elif sys.argv[1] == "rollback":
            backup_dir = sys.argv[2] if len(sys.argv) > 2 else None
            if backup_dir:
                success = manager.rollback(backup_dir)
                sys.exit(0 if success else 1)
            else:
                print("Please specify backup directory for rollback")
                sys.exit(1)
    else:
        print("Usage: python deployment_automation.py [deploy|rollback] [branch|backup_dir]")
        sys.exit(1)
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ»æœ€é©åŒ–

### ğŸ” APMï¼ˆApplication Performance Monitoringï¼‰

```python
# monitoring/apm_integration.py
from django.middleware.base import BaseMiddleware
from django.utils.deprecation import MiddlewareMixin
import time
import logging
import psutil
from datetime import datetime

logger = logging.getLogger(__name__)

class PerformanceMonitoringMiddleware(MiddlewareMixin):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ€§èƒ½ç›£è¦–ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢"""
    
    def process_request(self, request):
        request.start_time = time.time()
        request.start_memory = psutil.Process().memory_info().rss
    
    def process_response(self, request, response):
        if hasattr(request, 'start_time'):
            duration = time.time() - request.start_time
            memory_used = psutil.Process().memory_info().rss - request.start_memory
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
            performance_data = {
                'timestamp': datetime.now().isoformat(),
                'method': request.method,
                'path': request.path,
                'status_code': response.status_code,
                'duration_ms': round(duration * 1000, 2),
                'memory_mb': round(memory_used / 1024 / 1024, 2),
                'user_agent': request.META.get('HTTP_USER_AGENT', ''),
                'remote_addr': request.META.get('REMOTE_ADDR', ''),
            }
            
            # è­¦å‘Šãƒ¬ãƒ™ãƒ«ã®æ€§èƒ½å•é¡Œã‚’ãƒ­ã‚°
            if duration > 2.0:  # 2ç§’ä»¥ä¸Š
                logger.warning(f"Slow request detected: {performance_data}")
            elif duration > 1.0:  # 1ç§’ä»¥ä¸Š
                logger.info(f"Performance concern: {performance_data}")
            
            # Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°ï¼ˆå®Ÿè£…æ™‚ï¼‰
            # self.update_prometheus_metrics(performance_data)
        
        return response
    
    def update_prometheus_metrics(self, data):
        """Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°"""
        # from prometheus_client import Counter, Histogram
        # REQUEST_COUNT.labels(method=data['method'], endpoint=data['path']).inc()
        # REQUEST_LATENCY.observe(data['duration_ms'] / 1000)
        pass
```

### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ€§èƒ½ç›£è¦–

```sql
-- monitoring/db_performance_queries.sql

-- å®Ÿè¡Œæ™‚é–“ã®é•·ã„ã‚¯ã‚¨ãƒª
SELECT 
    query,
    mean_time,
    calls,
    total_time,
    (total_time/calls) as avg_time_ms
FROM pg_stat_statements 
WHERE mean_time > 100  -- 100msä»¥ä¸Š
ORDER BY mean_time DESC 
LIMIT 10;

-- ãƒ†ãƒ¼ãƒ–ãƒ«ã‚µã‚¤ã‚ºç›£è¦–
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
    pg_total_relation_size(schemaname||'.'||tablename) as size_bytes
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY size_bytes DESC;

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes 
WHERE idx_scan < 100  -- ã‚ã¾ã‚Šä½¿ã‚ã‚Œã¦ã„ãªã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
ORDER BY idx_scan;

-- ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ¥ç¶šç›£è¦–
SELECT 
    pid,
    usename,
    application_name,
    client_addr,
    state,
    query_start,
    state_change,
    query
FROM pg_stat_activity 
WHERE state != 'idle';
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ»å•é¡Œè§£æ±º

### ğŸš¨ ä¸€èˆ¬çš„ãªå•é¡Œã¨è§£æ±ºç­–

```bash
# monitoring/troubleshooting_guide.sh

#!/bin/bash
echo "=== ShiftMaster ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰ ==="

# 1. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒèµ·å‹•ã—ãªã„
check_application_startup() {
    echo "1. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•å•é¡Œã®è¨ºæ–­..."
    
    # ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ç¢ºèª
    systemctl status shiftmaster
    
    # ãƒ­ã‚°ç¢ºèª
    echo "æœ€æ–°ã®ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°:"
    tail -50 /var/log/shiftmaster/error.log
    
    # ãƒãƒ¼ãƒˆä½¿ç”¨çŠ¶æ³
    echo "ãƒãƒ¼ãƒˆ8000ã®ä½¿ç”¨çŠ¶æ³:"
    netstat -tulpn | grep 8000
    
    # ä»®æƒ³ç’°å¢ƒç¢ºèª
    echo "Pythonä»®æƒ³ç’°å¢ƒ:"
    which python
    python --version
}

# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼
check_database_connection() {
    echo "2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå•é¡Œã®è¨ºæ–­..."
    
    # PostgreSQLçŠ¶æ…‹ç¢ºèª
    systemctl status postgresql
    
    # æ¥ç¶šãƒ†ã‚¹ãƒˆ
    sudo -u postgres psql -c "SELECT version();"
    
    # æ¥ç¶šæ•°ç¢ºèª
    sudo -u postgres psql -c "SELECT count(*) FROM pg_stat_activity;"
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å­˜åœ¨ç¢ºèª
    sudo -u postgres psql -c "\l" | grep shiftmaster
}

# 3. é«˜CPUä½¿ç”¨ç‡
check_high_cpu() {
    echo "3. é«˜CPUä½¿ç”¨ç‡ã®è¨ºæ–­..."
    
    # ãƒ—ãƒ­ã‚»ã‚¹åˆ¥CPUä½¿ç”¨ç‡
    ps aux --sort=-%cpu | head -10
    
    # ã‚·ã‚¹ãƒ†ãƒ è² è·
    uptime
    
    # Djangoãƒ—ãƒ­ã‚»ã‚¹è©³ç´°
    ps aux | grep python | grep manage.py
    
    # å®Ÿè¡Œä¸­ã®ã‚¯ã‚¨ãƒª
    sudo -u postgres psql -d shiftmaster -c "SELECT pid, query_start, state, query FROM pg_stat_activity WHERE state = 'active';"
}

# 4. ãƒ¡ãƒ¢ãƒªä¸è¶³
check_memory_issues() {
    echo "4. ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ã®è¨ºæ–­..."
    
    # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è©³ç´°
    free -h
    cat /proc/meminfo | grep -E "(MemTotal|MemFree|MemAvailable|Cached|Buffers)"
    
    # ãƒ—ãƒ­ã‚»ã‚¹åˆ¥ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
    ps aux --sort=-%mem | head -10
    
    # ã‚¹ãƒ¯ãƒƒãƒ—ä½¿ç”¨çŠ¶æ³
    swapon --show
    
    # OOM Killerå±¥æ­´
    dmesg | grep -i "killed process"
}

# 5. ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡å•é¡Œ
check_disk_space() {
    echo "5. ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã®è¨ºæ–­..."
    
    # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
    df -h
    
    # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    du -sh /var/log/* | sort -hr | head -10
    du -sh /var/lib/postgresql/* | sort -hr | head -10
    
    # ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ³
    ls -la /var/log/shiftmaster/
    
    # inodeã®ä½¿ç”¨çŠ¶æ³
    df -i
}

# 6. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œ
check_network_issues() {
    echo "6. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œã®è¨ºæ–­..."
    
    # ãƒªã‚¹ãƒ‹ãƒ³ã‚°ãƒãƒ¼ãƒˆ
    netstat -tulpn | grep -E "(80|443|8000|5432|6379)"
    
    # ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«çŠ¶æ…‹
    ufw status
    iptables -L
    
    # å¤–éƒ¨æ¥ç¶šãƒ†ã‚¹ãƒˆ
    curl -I http://localhost:8000/health/
    
    # DNSè§£æ±ºãƒ†ã‚¹ãƒˆ
    nslookup $(hostname)
}

# ãƒ¡ã‚¤ãƒ³è¨ºæ–­å®Ÿè¡Œ
run_full_diagnosis() {
    echo "ShiftMaster ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨è¨ºæ–­é–‹å§‹: $(date)"
    echo "=================================================="
    
    check_application_startup
    echo ""
    check_database_connection
    echo ""
    check_high_cpu
    echo ""
    check_memory_issues
    echo ""
    check_disk_space
    echo ""
    check_network_issues
    
    echo "=================================================="
    echo "è¨ºæ–­å®Œäº†: $(date)"
}

# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã«å¿œã˜ã¦å®Ÿè¡Œ
case "${1:-all}" in
    "app") check_application_startup ;;
    "db") check_database_connection ;;
    "cpu") check_high_cpu ;;
    "memory") check_memory_issues ;;
    "disk") check_disk_space ;;
    "network") check_network_issues ;;
    "all") run_full_diagnosis ;;
    *) 
        echo "Usage: $0 [app|db|cpu|memory|disk|network|all]"
        echo "  app     - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•å•é¡Œ"
        echo "  db      - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå•é¡Œ"
        echo "  cpu     - é«˜CPUä½¿ç”¨ç‡å•é¡Œ"
        echo "  memory  - ãƒ¡ãƒ¢ãƒªä¸è¶³å•é¡Œ"
        echo "  disk    - ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡å•é¡Œ"
        echo "  network - ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œ"
        echo "  all     - å…¨é …ç›®è¨ºæ–­ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰"
        ;;
esac
```

## ğŸ“ ãƒ­ã‚°ç®¡ç†ãƒ»åˆ†æ

### ğŸ—‚ï¸ ãƒ­ã‚°çµ±åˆãƒ»é›†ç´„

```yaml
# monitoring/log_aggregation.yml
# ELK Stack (Elasticsearch, Logstash, Kibana) è¨­å®š

version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"

  logstash:
    image: docker.elastic.co/logstash/logstash:8.5.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - "5044:5044"
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.0
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.5.0
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/log/shiftmaster:/var/log/shiftmaster:ro
    depends_on:
      - logstash

volumes:
  elasticsearch_data:
```

```yaml
# monitoring/filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/shiftmaster/*.log
  fields:
    service: shiftmaster
    environment: production
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after

output.logstash:
  hosts: ["logstash:5044"]

processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
```

```ruby
# monitoring/logstash.conf
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "shiftmaster" {
    grok {
      match => { 
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{DATA:logger}: %{GREEDYDATA:message}" 
      }
    }
    
    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss,SSS" ]
    }
    
    if [level] in ["ERROR", "CRITICAL"] {
      mutate {
        add_tag => [ "alert" ]
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "shiftmaster-logs-%{+YYYY.MM.dd}"
  }
}
```

---

ã“ã®ã‚¬ã‚¤ãƒ‰ã«ã‚ˆã‚Šã€ShiftMasterã‚·ã‚¹ãƒ†ãƒ ã®åŒ…æ‹¬çš„ãªé‹ç”¨ç®¡ç†ãƒ»ç›£è¦–ä½“åˆ¶ãŒç¢ºç«‹ã•ã‚Œã¾ã™ã€‚24æ™‚é–“365æ—¥ã®å®‰å®šç¨¼åƒã‚’å®Ÿç¾ã—ã€åŒ»ç™‚æ©Ÿé–¢ã§ã®å®‰å¿ƒãƒ»å®‰å…¨ãªé‹ç”¨ã‚’æ”¯æ´ã—ã¾ã™ã€‚

**æœ€çµ‚æ›´æ–°**: 2024å¹´1æœˆ20æ—¥  
**å¯¾è±¡ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: ShiftMaster 2.0.0  
**ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹æ‹…å½“**: ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ãƒãƒ¼ãƒ 
